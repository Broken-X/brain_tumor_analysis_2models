# -*- coding: utf-8 -*-
"""Brain Tumor Gemini.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X7n0lEE-La_AJSrS_jVBCL8wMJtuy5VY
"""

# 1. SETUP & DATA DOWNLOAD
import kagglehub
DATA_ROOT = kagglehub.dataset_download("masoudnickparvar/brain-tumor-mri-dataset")

# 2. LIBRARIES
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support
import cv2

# 3. HYPERPARAMETERS & PREPROCESSING
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 32
IMG_SIZE = 224
EPOCHS = 10
NUM_CLASSES = 4

# Identical Data Augmentation & Preprocessing
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = os.path.join(DATA_ROOT, "Training")
test_dir  = os.path.join(DATA_ROOT, "Testing")

train_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])
test_dataset = datasets.ImageFolder(test_dir, data_transforms['test'])

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# 4. MODEL INITIALIZATION FUNCTION
def get_model(name):
    if name == 'resnet50':
        model = models.resnet50(weights='IMAGENET1K_V1')
        model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)
    elif name == 'efficientnet_b0':
        model = models.efficientnet_b0(weights='IMAGENET1K_V1')
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)
    elif name == 'densenet121':
        model = models.densenet121(weights='IMAGENET1K_V1')
        model.classifier = nn.Linear(model.classifier.in_features, NUM_CLASSES)
    return model.to(DEVICE)

# 5. TRAINING & EVALUATION LOOP
results = {}

# Create a directory for saved models
SAVE_DIR = "brain_tumor_models"
os.makedirs(SAVE_DIR, exist_ok=True)

model_names = ['resnet50', 'efficientnet_b0', 'densenet121']

for name in model_names:
    print(f"\n--- Training {name} ---")
    model = get_model(name)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    # Training
    model.train()
    for epoch in range(EPOCHS):
        print(f"--- Epoch {epoch} ---")
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Inference Latency & Accuracy
    model.eval()
    all_preds = []
    all_labels = []
    start_time = time.time()

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(DEVICE)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())

    end_time = time.time()
    latency = (end_time - start_time) / len(test_dataset) * 1000 # ms per image

    # Metrics
    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')
    params = sum(p.numel() for p in model.parameters())

    results[name] = {
        'latency_ms': latency,
        'params_M': params / 1e6,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'cm': confusion_matrix(all_labels, all_preds)
    }

    save_path = os.path.join(SAVE_DIR, f"{name}_brain_tumor.pth")
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': {'f1': f1, 'precision': precision, 'recall': recall},
        'class_names': train_dataset.classes
    }, save_path)
    print(f"Successfully saved {name} to {save_path}")

# 6. CREATE COMPARISON TABLE

df_results = pd.DataFrame(results).T.drop(columns='cm')
print("\n--- Model Comparison Table ---")
print(df_results)

# Plot Confusion Matrices
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
class_names = train_dataset.classes

for i, name in enumerate(model_names):
    sns.heatmap(results[name]['cm'], annot=True, fmt='d', cmap='Blues', ax=axes[i],
                xticklabels=class_names, yticklabels=class_names)
    axes[i].set_title(f'Confusion Matrix: {name}')
    axes[i].set_xlabel('Predicted')
    axes[i].set_ylabel('Actual')

plt.tight_layout()
plt.show()

# 7. GRAD-CAM VISUALIZATION
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output): self.activations = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]

    def generate(self, input_tensor, class_idx):
        output = self.model(input_tensor)
        self.model.zero_grad()
        output[0, class_idx].backward()

        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        cam = torch.sum(weights * self.activations, dim=1).squeeze().detach().cpu().numpy()
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (IMG_SIZE, IMG_SIZE))
        return (cam - cam.min()) / (cam.max() - cam.min())

# Example Grad-CAM for ResNet50
# target_layer: model.layer4 for ResNet, model.features for EfficientNet/DenseNet